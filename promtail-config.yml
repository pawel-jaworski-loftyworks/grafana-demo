server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Scrape Docker container logs
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      # Only scrape logs from our services
      - source_labels: ['__meta_docker_container_name']
        regex: '/(user-service|document-service|permission-service)'
        action: keep

      # Extract service name from container name (this becomes a label)
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container_name'

    # Pipeline to parse JSON logs
    pipeline_stages:
      # Parse JSON logs from Spring Boot services
      - json:
          expressions:
            timestamp: timestamp
            level: level
            logger: logger
            message: message
            thread: thread
            application: application
            requestId: requestId
            appId: appId
            userId: userId
            stack_trace: stack_trace

      # Extract timestamp if available
      - timestamp:
          source: timestamp
          format: RFC3339

      # Set static label for job to ensure at least one label exists
      - static_labels:
          job: docker

      # Set labels from JSON if available
      # WARNING: requestId has high cardinality but is included as a label for easier filtering
      - labels:
          application:
          level:
          requestId:

      # Keep other high-cardinality fields as structured metadata (not labels!)
      # This makes them searchable and filterable without creating high cardinality issues
      - structured_metadata:
          stack_trace:
          logger:
          thread:
          appId:
          userId:

      # Output just the message (other fields are in structured metadata)
      - output:
          source: message

